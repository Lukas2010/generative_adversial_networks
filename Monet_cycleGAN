{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.18","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":21755,"databundleVersionId":1475600,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Upgrade tensorflow\nI initially had big problems using the older version of tensorflow. I could make it work with tensorflow 2.19. Therefore i needed to include the following ugly block of upgrade updates.","metadata":{}},{"cell_type":"code","source":"!pip install -q -U tensorflow==2.19.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:45:07.780766Z","iopub.execute_input":"2025-07-17T15:45:07.781057Z","iopub.status.idle":"2025-07-17T15:46:45.182687Z","shell.execute_reply.started":"2025-07-17T15:45:07.781033Z","shell.execute_reply":"2025-07-17T15:46:45.178862Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Now i import the required libraries**","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd \nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport keras\nfrom keras import layers, ops\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Lets check if we have the correct version of tensorflow.","metadata":{}},{"cell_type":"code","source":"print(tf.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:47:07.865264Z","iopub.execute_input":"2025-07-17T15:47:07.865651Z","iopub.status.idle":"2025-07-17T15:47:07.875756Z","shell.execute_reply.started":"2025-07-17T15:47:07.865628Z","shell.execute_reply":"2025-07-17T15:47:07.870193Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Import","metadata":{}},{"cell_type":"code","source":"main_dir = \"/kaggle/input/gan-getting-started\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:47:07.877282Z","iopub.execute_input":"2025-07-17T15:47:07.877507Z","iopub.status.idle":"2025-07-17T15:47:07.893452Z","shell.execute_reply.started":"2025-07-17T15:47:07.877486Z","shell.execute_reply":"2025-07-17T15:47:07.889046Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"The directories for the data are: \", os.listdir(main_dir))\n\nmonet_dir = str(main_dir + \"/\" + os.listdir(main_dir)[0])\nphoto_dir = str(main_dir + \"/\" + os.listdir(main_dir)[2])\n\nprint(\"The number of Monet images is: \", len(os.listdir(monet_dir)))\nprint(\"The number of Photo images is: \", len(os.listdir(photo_dir)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:47:07.894990Z","iopub.execute_input":"2025-07-17T15:47:07.895360Z","iopub.status.idle":"2025-07-17T15:47:08.235550Z","shell.execute_reply.started":"2025-07-17T15:47:07.895340Z","shell.execute_reply":"2025-07-17T15:47:08.230730Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"I decided to use the jpg images from the folders and import them in small batches.","metadata":{}},{"cell_type":"code","source":"img_size = (256,256)\n\nmonet_dataset = keras.utils.image_dataset_from_directory(\n    monet_dir, label_mode=None, image_size=img_size, batch_size=6\n)\n\nphoto_dataset = keras.utils.image_dataset_from_directory(\n    photo_dir, label_mode=None, image_size=img_size, batch_size=6\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:47:08.236978Z","iopub.execute_input":"2025-07-17T15:47:08.237167Z","iopub.status.idle":"2025-07-17T15:47:24.711023Z","shell.execute_reply.started":"2025-07-17T15:47:08.237148Z","shell.execute_reply":"2025-07-17T15:47:24.706747Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The two datasets are imported in batches meaning the total number of files reduces by a factor of 6. Lets check if that turns out correctly.","metadata":{}},{"cell_type":"code","source":"print(photo_dataset.cardinality().numpy())\nprint(monet_dataset.cardinality().numpy())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:47:24.713269Z","iopub.execute_input":"2025-07-17T15:47:24.713509Z","iopub.status.idle":"2025-07-17T15:47:24.722151Z","shell.execute_reply.started":"2025-07-17T15:47:24.713487Z","shell.execute_reply":"2025-07-17T15:47:24.717870Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data preprocessing\n","metadata":{}},{"cell_type":"markdown","source":"What do the pictures look like?","metadata":{}},{"cell_type":"markdown","source":"i = 0\nfor x in monet_dataset:\n    plt.subplot(1,5,i+1)\n    plt.title('Monet')\n    plt.imshow(x[0] * 0.5 + 0.5)\n    plt.axis(\"off\")\n    i += 1\n    if i == 5:\n        break\n\ni = 0\nfor x in photo_dataset:\n    plt.subplot(2,5,i+1)\n    plt.title('Photo')\n    plt.imshow(x[0] * 0.5 + 0.5)\n    plt.axis(\"off\")\n    i += 1\n    if i == 5:\n        break","metadata":{"execution":{"iopub.status.busy":"2025-07-17T07:19:30.601336Z","iopub.execute_input":"2025-07-17T07:19:30.601585Z","iopub.status.idle":"2025-07-17T07:19:31.307055Z","shell.execute_reply.started":"2025-07-17T07:19:30.601564Z","shell.execute_reply":"2025-07-17T07:19:31.302472Z"}}},{"cell_type":"markdown","source":"Next we will need to reshape the images to uniform distribution (-1,1). ","metadata":{}},{"cell_type":"code","source":"photo_dataset = photo_dataset.map(lambda x: (x /  127.5)-1)\nmonet_dataset = monet_dataset.map(lambda x: (x /  127.5)-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:47:24.724078Z","iopub.execute_input":"2025-07-17T15:47:24.724316Z","iopub.status.idle":"2025-07-17T15:47:24.768964Z","shell.execute_reply.started":"2025-07-17T15:47:24.724294Z","shell.execute_reply":"2025-07-17T15:47:24.764921Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for x in monet_dataset:\n    plt.axis(\"off\")\n    plt.imshow(((x.numpy() +1 ) * 127.5).astype(\"int32\")[0])\n    break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:47:24.771580Z","iopub.execute_input":"2025-07-17T15:47:24.771801Z","iopub.status.idle":"2025-07-17T15:47:25.082767Z","shell.execute_reply.started":"2025-07-17T15:47:24.771781Z","shell.execute_reply":"2025-07-17T15:47:25.077319Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for x in photo_dataset:\n    plt.axis(\"off\")\n    plt.imshow(((x.numpy() +1 ) * 127.5).astype(\"int32\")[0])\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:47:25.084169Z","iopub.execute_input":"2025-07-17T15:47:25.084398Z","iopub.status.idle":"2025-07-17T15:47:25.268586Z","shell.execute_reply.started":"2025-07-17T15:47:25.084376Z","shell.execute_reply":"2025-07-17T15:47:25.262915Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Define model\n\nThis project os inspired by the excellent GAN Tutorial from Amy Jang which can be found here:\nhttps://www.kaggle.com/code/amyjang/monet-cyclegan-tutorial\n\nThis project makes use of a U-Net. The U-Net has its name from the shape of if layers in which a Decoder uses small filters and a MaxPooling operation or larger strides in the filter to reduce the dimensions of the picture aggressively. After that it rebuilds the image using a decoder. The two sides of the U shaped layers are connected by skip connections which help retain some of the information that would be lost otherwise due to the aggressive downsampling of the features. \n\nMy code changes the weights of the layers, introduced BatchNormalization and adds a transformation layer at the bottom of the U which can be found in many other cycleGANs. \n\nA nice description of the U-Net can be found here:\nhttps://www.geeksforgeeks.org/machine-learning/u-net-architecture-explained/\n\nThe cycle GAN makes use of the general GAN structure in which a generator creates a fake image and tries to fool the discriminator. In the case of the cycle GAN and unlike the general GAN we can use unpaired data in which one part of the data represents a feature or style we want to create while we don't have an exact pair of this data.\nTherefore the cycle GAN makes use of an additional generator wich translates the fake image back to its original in order to make sure that the generated image still retains most features of the original image. The loss is then calculated after both generators first create the fake image and then recreate the real image.\n\nAgain a nice description can be found here:\nhttps://www.geeksforgeeks.org/machine-learning/cycle-generative-adversarial-network-cyclegan-2/\n\nand here:\nhttps://www.youtube.com/watch?v=-8hfnlxEPn4","metadata":{}},{"cell_type":"markdown","source":"**Upsampling/Encoding**\n\nHere the upsampling function is defined.","metadata":{}},{"cell_type":"code","source":"def upsample(filters, size, apply_dropout=False):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n\n    result = keras.Sequential()\n    result.add(layers.Conv2DTranspose(filters, size, strides=2,\n                                      padding='same',\n                                      kernel_initializer=initializer,\n                                      use_bias=False))\n\n    result.add(layers.BatchNormalization(gamma_initializer = gamma_init))\n\n    if apply_dropout:\n        result.add(layers.Dropout(0.5))\n\n    result.add(layers.ReLU())\n\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:57:15.545648Z","iopub.execute_input":"2025-07-17T15:57:15.545970Z","iopub.status.idle":"2025-07-17T15:57:15.557437Z","shell.execute_reply.started":"2025-07-17T15:57:15.545929Z","shell.execute_reply":"2025-07-17T15:57:15.552675Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Downsampling/Decoding**\n\nHere the Downsampling function is defined which decreases the number of features by applying an aggressive filter with stride = 2","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"OUTPUT_CHANNELS = 3\n\ndef downsample(filters, size):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n\n    result = keras.Sequential()\n    result.add(layers.Conv2D(filters, size, strides=2, padding='same',\n                             kernel_initializer=initializer, use_bias=False))\n    result.add(layers.BatchNormalization(gamma_initializer = gamma_init))\n\n    result.add(layers.LeakyReLU())\n\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:57:15.559979Z","iopub.execute_input":"2025-07-17T15:57:15.560188Z","iopub.status.idle":"2025-07-17T15:57:15.573622Z","shell.execute_reply.started":"2025-07-17T15:57:15.560168Z","shell.execute_reply":"2025-07-17T15:57:15.569423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef transformer(filters, size):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n\n    result = keras.Sequential()\n    result.add(layers.Conv2D(filters, size, strides=1, padding='same',\n                             kernel_initializer=initializer, use_bias=False))\n    result.add(layers.BatchNormalization(gamma_initializer = gamma_init))\n\n    result.add(layers.LeakyReLU())\n\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:57:15.575805Z","iopub.execute_input":"2025-07-17T15:57:15.577364Z","iopub.status.idle":"2025-07-17T15:57:15.587195Z","shell.execute_reply.started":"2025-07-17T15:57:15.577342Z","shell.execute_reply":"2025-07-17T15:57:15.582326Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Generator**","metadata":{}},{"cell_type":"code","source":"def Generator():\n    inputs = layers.Input(shape=[256,256,3])\n\n    # bs = batch size\n    down_stack = [\n        downsample(64, 4), # (bs, 128, 128, 64)\n        downsample(128, 4), # (bs, 64, 64, 128)\n        downsample(256, 4), # (bs, 32, 32, 256) \n        downsample(512, 4), # (bs, 16, 16, 512)\n        downsample(1024, 4), # (bs, 8, 8, 512)\n        downsample(1024, 4), # (bs, 4, 4, 512)\n        #downsample(1024, 4), # (bs, 2, 2, 512)\n        #downsample(1024, 4), # (bs, 1, 1, 512)\n    ]\n\n    up_stack = [\n        #upsample(1024, 4, apply_dropout=True), # (bs, 2, 2, 1024)\n        #upsample(256, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n        upsample(1024, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n        upsample(512, 4), # (bs, 16, 16, 1024)\n        upsample(256, 4), # (bs, 32, 32, 512)\n        upsample(128, 4), # (bs, 64, 64, 256)\n        upsample(64, 4), # (bs, 128, 128, 128)\n    ]\n\n    # Transformer\n    transformer_stack = [\n        transformer(1024,3), #keeps size of data\n        transformer(1024,3),\n        transformer(1024,3),\n        transformer(1024,3)\n    ]\n    \n    initializer = tf.random_normal_initializer(0., 0.02)\n    last = layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n                                  strides=2,\n                                  padding='same',\n                                  kernel_initializer=initializer,\n                                  activation='tanh') # (bs, 256, 256, 3)\n\n    x = inputs\n\n    # Downsampling through the model\n    skips = []\n    for down in down_stack:\n        x = down(x)\n        skips.append(x)\n\n    skips = reversed(skips[:-1])\n\n    for transform in transformer_stack:\n        x = transform(x)\n    \n    # Upsampling and establishing the skip connections\n    for up, skip in zip(up_stack, skips):\n        x = up(x)\n        x = layers.Concatenate()([x, skip])\n\n    x = last(x)\n\n    return keras.Model(inputs=inputs, outputs=x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:57:15.588871Z","iopub.execute_input":"2025-07-17T15:57:15.589215Z","iopub.status.idle":"2025-07-17T15:57:15.606130Z","shell.execute_reply.started":"2025-07-17T15:57:15.589189Z","shell.execute_reply":"2025-07-17T15:57:15.601006Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Discriminator**","metadata":{}},{"cell_type":"code","source":"def Discriminator():\n    initializer = tf.random_normal_initializer(0., 0.02)\n    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n\n    inp = layers.Input(shape=[256, 256, 3], name='input_image')\n\n    x = inp\n\n    down1 = downsample(64, 4)(x) # (bs, 128, 128, 64)\n    down2 = downsample(64, 4)(down1) # (bs, 64, 64, 128)\n    down3 = downsample(256, 4)(down2) # (bs, 32, 32, 256)\n\n    zero_pad1 = layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n    conv = layers.Conv2D(512, 4, strides=1,\n                         kernel_initializer=initializer,\n                         use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n\n    leaky_relu = layers.LeakyReLU()(conv)\n\n    zero_pad2 = layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n\n    last = layers.Conv2D(1, 4, strides=1,\n                         kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n\n    return tf.keras.Model(inputs=inp, outputs=last)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:57:15.608313Z","iopub.execute_input":"2025-07-17T15:57:15.608545Z","iopub.status.idle":"2025-07-17T15:57:15.624232Z","shell.execute_reply.started":"2025-07-17T15:57:15.608524Z","shell.execute_reply":"2025-07-17T15:57:15.617934Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Initialize classes**","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    monet_generator = Generator() # transforms photos to Monet-esque paintings\n    photo_generator = Generator() # transforms Monet paintings to be more like photos\n\n    monet_discriminator = Discriminator() # differentiates real Monet paintings and generated Monet paintings\n    photo_discriminator = Discriminator() # differentiates real photos and generated photos","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:57:15.626808Z","iopub.execute_input":"2025-07-17T15:57:15.627021Z","iopub.status.idle":"2025-07-17T15:57:16.325009Z","shell.execute_reply.started":"2025-07-17T15:57:15.627001Z","shell.execute_reply":"2025-07-17T15:57:16.318304Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"example_monet = next(iter(monet_dataset))\nexample_photo = next(iter(photo_dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:57:16.325666Z","iopub.execute_input":"2025-07-17T15:57:16.325860Z","iopub.status.idle":"2025-07-17T15:57:16.432972Z","shell.execute_reply.started":"2025-07-17T15:57:16.325840Z","shell.execute_reply":"2025-07-17T15:57:16.427798Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"to_monet = monet_generator(example_photo)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:57:16.436174Z","iopub.execute_input":"2025-07-17T15:57:16.436490Z","iopub.status.idle":"2025-07-17T15:57:16.681726Z","shell.execute_reply.started":"2025-07-17T15:57:16.436392Z","shell.execute_reply":"2025-07-17T15:57:16.676676Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.subplot(1, 2, 1)\nplt.title(\"Original Photo\")\nplt.imshow(example_photo[0] * 0.5 + 0.5)\n\nplt.subplot(1, 2, 2)\nplt.title(\"Monet-esque Photo\")\nplt.imshow(to_monet[0] * 0.5 + 0.5)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:57:16.683656Z","iopub.execute_input":"2025-07-17T15:57:16.683922Z","iopub.status.idle":"2025-07-17T15:57:16.902849Z","shell.execute_reply.started":"2025-07-17T15:57:16.683901Z","shell.execute_reply":"2025-07-17T15:57:16.897781Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Define GAN Class**","metadata":{}},{"cell_type":"code","source":"class CycleGan(keras.Model):\n    def __init__(\n        self,\n        monet_generator,\n        photo_generator,\n        monet_discriminator,\n        photo_discriminator,\n        lambda_cycle=10,\n    ):\n        super(CycleGan, self).__init__()\n        self.m_gen = monet_generator\n        self.p_gen = photo_generator\n        self.m_disc = monet_discriminator\n        self.p_disc = photo_discriminator\n        self.lambda_cycle = lambda_cycle\n        \n    def compile(\n        self,\n        m_gen_optimizer,\n        p_gen_optimizer,\n        m_disc_optimizer,\n        p_disc_optimizer,\n        gen_loss_fn,\n        disc_loss_fn,\n        cycle_loss_fn,\n        identity_loss_fn\n    ):\n        super(CycleGan, self).compile()\n        self.m_gen_optimizer = m_gen_optimizer\n        self.p_gen_optimizer = p_gen_optimizer\n        self.m_disc_optimizer = m_disc_optimizer\n        self.p_disc_optimizer = p_disc_optimizer\n        self.gen_loss_fn = gen_loss_fn\n        self.disc_loss_fn = disc_loss_fn\n        self.cycle_loss_fn = cycle_loss_fn\n        self.identity_loss_fn = identity_loss_fn\n        \n    def train_step(self, batch_data):\n        real_monet, real_photo = batch_data\n        \n        with tf.GradientTape(persistent=True) as tape:\n            # photo to monet back to photo\n            fake_monet = self.m_gen(real_photo, training=True)\n            cycled_photo = self.p_gen(fake_monet, training=True)\n\n            # monet to photo back to monet\n            fake_photo = self.p_gen(real_monet, training=True)\n            cycled_monet = self.m_gen(fake_photo, training=True)\n\n            # generating itself\n            same_monet = self.m_gen(real_monet, training=True)\n            same_photo = self.p_gen(real_photo, training=True)\n\n            # discriminator used to check, inputing real images\n            disc_real_monet = self.m_disc(real_monet, training=True)\n            disc_real_photo = self.p_disc(real_photo, training=True)\n\n            # discriminator used to check, inputing fake images\n            disc_fake_monet = self.m_disc(fake_monet, training=True)\n            disc_fake_photo = self.p_disc(fake_photo, training=True)\n\n            # evaluates generator loss\n            monet_gen_loss = self.gen_loss_fn(disc_fake_monet)\n            photo_gen_loss = self.gen_loss_fn(disc_fake_photo)\n\n            # evaluates total cycle consistency loss\n            total_cycle_loss = self.cycle_loss_fn(real_monet, cycled_monet, self.lambda_cycle) + self.cycle_loss_fn(real_photo, cycled_photo, self.lambda_cycle)\n\n            # evaluates total generator loss\n            total_monet_gen_loss = monet_gen_loss + total_cycle_loss + self.identity_loss_fn(real_monet, same_monet, self.lambda_cycle)\n            total_photo_gen_loss = photo_gen_loss + total_cycle_loss + self.identity_loss_fn(real_photo, same_photo, self.lambda_cycle)\n\n            # evaluates discriminator loss\n            monet_disc_loss = self.disc_loss_fn(disc_real_monet, disc_fake_monet)\n            photo_disc_loss = self.disc_loss_fn(disc_real_photo, disc_fake_photo)\n\n        # Calculate the gradients for generator and discriminator\n        monet_generator_gradients = tape.gradient(total_monet_gen_loss,\n                                                  self.m_gen.trainable_variables)\n        photo_generator_gradients = tape.gradient(total_photo_gen_loss,\n                                                  self.p_gen.trainable_variables)\n\n        monet_discriminator_gradients = tape.gradient(monet_disc_loss,\n                                                      self.m_disc.trainable_variables)\n        photo_discriminator_gradients = tape.gradient(photo_disc_loss,\n                                                      self.p_disc.trainable_variables)\n\n        # Apply the gradients to the optimizer\n        self.m_gen_optimizer.apply_gradients(zip(monet_generator_gradients,\n                                                 self.m_gen.trainable_variables))\n\n        self.p_gen_optimizer.apply_gradients(zip(photo_generator_gradients,\n                                                 self.p_gen.trainable_variables))\n\n        self.m_disc_optimizer.apply_gradients(zip(monet_discriminator_gradients,\n                                                  self.m_disc.trainable_variables))\n\n        self.p_disc_optimizer.apply_gradients(zip(photo_discriminator_gradients,\n                                                  self.p_disc.trainable_variables))\n        \n        return {\n            \"monet_gen_loss\": total_monet_gen_loss,\n            \"photo_gen_loss\": total_photo_gen_loss,\n            \"monet_disc_loss\": monet_disc_loss,\n            \"photo_disc_loss\": photo_disc_loss\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:57:16.904744Z","iopub.execute_input":"2025-07-17T15:57:16.904957Z","iopub.status.idle":"2025-07-17T15:57:16.923140Z","shell.execute_reply.started":"2025-07-17T15:57:16.904936Z","shell.execute_reply":"2025-07-17T15:57:16.918044Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with strategy.scope():\n    def discriminator_loss(real, generated):\n        real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.ones_like(real), real)\n\n        generated_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.zeros_like(generated), generated)\n\n        total_disc_loss = real_loss + generated_loss\n\n        return total_disc_loss * 0.5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:57:16.925294Z","iopub.execute_input":"2025-07-17T15:57:16.925543Z","iopub.status.idle":"2025-07-17T15:57:16.935976Z","shell.execute_reply.started":"2025-07-17T15:57:16.925520Z","shell.execute_reply":"2025-07-17T15:57:16.931832Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with strategy.scope():\n    def generator_loss(generated):\n        return tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.ones_like(generated), generated)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:57:16.938181Z","iopub.execute_input":"2025-07-17T15:57:16.938381Z","iopub.status.idle":"2025-07-17T15:57:16.946759Z","shell.execute_reply.started":"2025-07-17T15:57:16.938362Z","shell.execute_reply":"2025-07-17T15:57:16.943453Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    def calc_cycle_loss(real_image, cycled_image, LAMBDA):\n        loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n\n        return LAMBDA * loss1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:57:16.949975Z","iopub.execute_input":"2025-07-17T15:57:16.950175Z","iopub.status.idle":"2025-07-17T15:57:16.960207Z","shell.execute_reply.started":"2025-07-17T15:57:16.950156Z","shell.execute_reply":"2025-07-17T15:57:16.955138Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with strategy.scope():\n    def identity_loss(real_image, same_image, LAMBDA):\n        loss = tf.reduce_mean(tf.abs(real_image - same_image))\n        return LAMBDA * 0.5 * loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:57:16.962477Z","iopub.execute_input":"2025-07-17T15:57:16.962808Z","iopub.status.idle":"2025-07-17T15:57:16.972563Z","shell.execute_reply.started":"2025-07-17T15:57:16.962784Z","shell.execute_reply":"2025-07-17T15:57:16.968028Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with strategy.scope():\n    monet_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n    photo_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n\n    monet_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n    photo_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:57:16.974694Z","iopub.execute_input":"2025-07-17T15:57:16.974895Z","iopub.status.idle":"2025-07-17T15:57:16.991190Z","shell.execute_reply.started":"2025-07-17T15:57:16.974867Z","shell.execute_reply":"2025-07-17T15:57:16.987364Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with strategy.scope():\n    cycle_gan_model = CycleGan(\n        monet_generator, photo_generator, monet_discriminator, photo_discriminator\n    )\n\n    cycle_gan_model.compile(\n        m_gen_optimizer = monet_generator_optimizer,\n        p_gen_optimizer = photo_generator_optimizer,\n        m_disc_optimizer = monet_discriminator_optimizer,\n        p_disc_optimizer = photo_discriminator_optimizer,\n        gen_loss_fn = generator_loss,\n        disc_loss_fn = discriminator_loss,\n        cycle_loss_fn = calc_cycle_loss,\n        identity_loss_fn = identity_loss\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:57:16.993871Z","iopub.execute_input":"2025-07-17T15:57:16.994094Z","iopub.status.idle":"2025-07-17T15:57:17.011113Z","shell.execute_reply.started":"2025-07-17T15:57:16.994073Z","shell.execute_reply":"2025-07-17T15:57:17.005605Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cycle_gan_model.fit(\n    tf.data.Dataset.zip((monet_dataset, photo_dataset)),\n    epochs=15,\n    verbose = 1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:57:17.013538Z","iopub.execute_input":"2025-07-17T15:57:17.013763Z","iopub.status.idle":"2025-07-17T15:59:30.070401Z","shell.execute_reply.started":"2025-07-17T15:57:17.013741Z","shell.execute_reply":"2025-07-17T15:59:30.064928Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nprint(\"The shape of our data is:\", example_monet.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:59:30.072921Z","iopub.execute_input":"2025-07-17T15:59:30.073185Z","iopub.status.idle":"2025-07-17T15:59:30.082582Z","shell.execute_reply.started":"2025-07-17T15:59:30.073161Z","shell.execute_reply":"2025-07-17T15:59:30.078704Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.subplot(121)\nplt.title('Photo')\nplt.imshow(example_photo[0] * 0.5 + 0.5)\n\nplt.subplot(122)\nplt.title('Monet')\nplt.imshow(example_monet[0] * 0.5 + 0.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:59:30.083426Z","iopub.execute_input":"2025-07-17T15:59:30.083659Z","iopub.status.idle":"2025-07-17T15:59:30.400360Z","shell.execute_reply.started":"2025-07-17T15:59:30.083636Z","shell.execute_reply":"2025-07-17T15:59:30.395719Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"_, ax = plt.subplots(5, 2, figsize=(16, 16))\nfor i, img in enumerate(photo_dataset.take(5)):\n    prediction = monet_generator(img, training=False)[0].numpy()\n    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n    img = (img[0] * 127.5 + 127.5).numpy().astype(np.uint8)\n\n    ax[i, 0].imshow(img)\n    ax[i, 1].imshow(prediction)\n    ax[i, 0].set_title(\"Input Photo\")\n    ax[i, 1].set_title(\"Monet inspired\")\n    ax[i, 0].axis(\"off\")\n    ax[i, 1].axis(\"off\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:59:30.401158Z","iopub.execute_input":"2025-07-17T15:59:30.401370Z","iopub.status.idle":"2025-07-17T15:59:32.364536Z","shell.execute_reply.started":"2025-07-17T15:59:30.401348Z","shell.execute_reply":"2025-07-17T15:59:32.358836Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nprediction = monet_generator(example_photo, training = False).numpy()\nprediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n\nfor x in prediction:\n    plt.imshow(x)\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:59:32.365490Z","iopub.execute_input":"2025-07-17T15:59:32.365740Z","iopub.status.idle":"2025-07-17T15:59:32.786274Z","shell.execute_reply.started":"2025-07-17T15:59:32.365714Z","shell.execute_reply":"2025-07-17T15:59:32.781459Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission file","metadata":{}},{"cell_type":"code","source":"import PIL\n! mkdir ../images","metadata":{"execution":{"iopub.status.busy":"2025-07-17T15:59:32.788391Z","iopub.execute_input":"2025-07-17T15:59:32.788838Z","iopub.status.idle":"2025-07-17T15:59:33.625536Z","shell.execute_reply.started":"2025-07-17T15:59:32.788811Z","shell.execute_reply":"2025-07-17T15:59:33.619703Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"i = 0\nfor img in photo_dataset:\n\n    prediction = monet_generator(img, training=False).numpy()\n    for pred_img in prediction:\n\n        pred_img = (pred_img * 127.5 + 127.5).astype(np.uint8)\n        im = PIL.Image.fromarray(pred_img)\n        im.save(\"../images/\" + str(i) + \".jpg\")\n        i += 1\n\n    if i > 7500:\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T15:59:33.628700Z","iopub.execute_input":"2025-07-17T15:59:33.628964Z","iopub.status.idle":"2025-07-17T15:59:57.619976Z","shell.execute_reply.started":"2025-07-17T15:59:33.628935Z","shell.execute_reply":"2025-07-17T15:59:57.613659Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\nshutil.make_archive(\"/kaggle/working/images\", 'zip', \"/kaggle/images\")","metadata":{"execution":{"iopub.status.busy":"2025-07-17T15:59:57.622461Z","iopub.status.idle":"2025-07-17T15:59:57.622991Z","shell.execute_reply.started":"2025-07-17T15:59:57.622673Z","shell.execute_reply":"2025-07-17T15:59:57.622686Z"},"trusted":true},"outputs":[],"execution_count":null}]}